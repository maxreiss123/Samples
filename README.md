# Introduction

The given repo serves as a placeholder for various prototypes and example projects, which will be transferred into a more mature project. Currently, it contains an example on how to employ a tokenizer from the Google library `sentencepiece`, within the keras `min-gpt' listing.
